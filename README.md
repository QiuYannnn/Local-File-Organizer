# Local File Organizer: AI File Management Run Entirely on Your Device, Privacy Assured

Tired of digital clutter? Overwhelmed by disorganized files scattered across your computer? Let AI do the heavy lifting! The Local File Organizer is your personal organizing assistant, using cutting-edge AI to bring order to your file chaos - all while respecting your privacy.

## How It Works ðŸ’¡

Before:

```
/home/user/messy_documents/
â”œâ”€â”€ IMG_20230515_140322.jpg
â”œâ”€â”€ IMG_20230516_083045.jpg
â”œâ”€â”€ IMG_20230517_192130.jpg
â”œâ”€â”€ budget_2023.xlsx
â”œâ”€â”€ meeting_notes_05152023.txt
â”œâ”€â”€ project_proposal_draft.docx
â”œâ”€â”€ random_thoughts.txt
â”œâ”€â”€ recipe_chocolate_cake.pdf
â”œâ”€â”€ scan0001.pdf
â”œâ”€â”€ vacation_itinerary.docx
â””â”€â”€ work_presentation.pptx

0 directories, 11 files
```

After:

```
/home/user/organized_documents/
â”œâ”€â”€ Financial
â”‚   â””â”€â”€ 2023_Budget_Spreadsheet.xlsx
â”œâ”€â”€ Food_and_Recipes
â”‚   â””â”€â”€ Chocolate_Cake_Recipe.pdf
â”œâ”€â”€ Meetings_and_Notes
â”‚   â””â”€â”€ Team_Meeting_Notes_May_15_2023.txt
â”œâ”€â”€ Personal
â”‚   â””â”€â”€ Random_Thoughts_and_Ideas.txt
â”œâ”€â”€ Photos
â”‚   â”œâ”€â”€ Cityscape_Sunset_May_17_2023.jpg
â”‚   â”œâ”€â”€ Morning_Coffee_Shop_May_16_2023.jpg
â”‚   â””â”€â”€ Office_Team_Lunch_May_15_2023.jpg
â”œâ”€â”€ Travel
â”‚   â””â”€â”€ Summer_Vacation_Itinerary_2023.docx
â””â”€â”€ Work
    â”œâ”€â”€ Project_X_Proposal_Draft.docx
    â”œâ”€â”€ Quarterly_Sales_Report.pdf
    â””â”€â”€ Marketing_Strategy_Presentation.pptx

7 directories, 11 files
```

## Updates ðŸš€

**[2024/09] v0.0.2**:
* Featured by [Nexa Gallery](https://nexaai.com/gallery) and [Nexa SDK Cookbook](https://github.com/NexaAI/nexa-sdk/tree/main/examples)!
* Dry Run Mode: check sorting results before committing changes
* Silent Mode: save all logs to a txt file for quieter operation
* Added file support:  `.md`, .`excel`, `.ppt`, and `.csv`
* Three sorting options: by content, by date, and by type
* The default text model is now [Llama3.2 3B](https://nexaai.com/meta/Llama3.2-3B-Instruct/gguf-q3_K_M/file)
* Improved CLI interaction experience
* Added real-time progress bar for file analysis

Please update the project by deleting the original project folder and reinstalling the requirements. Refer to the installation guide from Step 4.


## Roadmap ðŸ“…

- [x] Dockerfile for easier installation
- [ ] Copilot Mode: chat with AI to tell AI how you want to sort the file (ie. read and rename all the PDFs)
- [ ] Change models with CLI
- [ ] ebook format support
- [ ] audio file support
- [ ] video file support
- [ ] Implement best practices like Johnny Decimal
- [ ] Check file duplication
- [ ] People from [Nexa](https://github.com/NexaAI/nexa-sdk) is helping me to make executables for macOS, Linux and Windows

## What It Does ðŸ”

This intelligent file organizer harnesses the power of advanced AI models, including language models (LMs) and vision-language models (VLMs), to automate the process of organizing files by:


* Scanning a specified input directory for files.
* Content Understanding:
  - **Textual Analysis**: Uses the [Llama3.2 3B](https://nexaai.com/meta/Llama3.2-3B-Instruct/gguf-q3_K_M/file) to analyze and summarize text-based content, generating relevant descriptions and filenames.
  - **Visual Content Analysis**: Uses the [LLaVA-v1.6](https://nexaai.com/liuhaotian/llava-v1.6-vicuna-7b/gguf-q4_0/file) , based on Vicuna-7B, to interpret visual files such as images, providing context-aware categorization and descriptions.

* Understanding the content of your files (text, images, and more) to generate relevant descriptions, folder names, and filenames.
* Organizing the files into a new directory structure based on the generated metadata.

The best part? All AI processing happens 100% on your local device using the [Nexa SDK](https://github.com/NexaAI/nexa-sdk). No internet connection required, no data leaves your computer, and no AI API is needed - keeping your files completely private and secure.


## Supported File Types ðŸ“

- **Images:** `.png`, `.jpg`, `.jpeg`, `.gif`, `.bmp`
- **Text Files:** `.txt`, `.docx`, `.md`
- **Spreadsheets:** `.xlsx`, `.csv`
- **Presentations:** `.ppt`, `.pptx`
- **PDFs:** `.pdf`

## Prerequisites ðŸ’»

- **Operating System:** Compatible with Windows, macOS, and Linux.
- **Python Version:** Python 3.12
- **Conda:** Anaconda or Miniconda installed.
- **Git:** For cloning the repository (or you can download the code as a ZIP file).

## Installation ðŸ› 

> For SDK installation and model-related issues, please post on [here](https://github.com/NexaAI/nexa-sdk/issues).

### 1. Install Python

Before installing the Local File Organizer, make sure you have Python installed on your system. We recommend using Python 3.12 or later.

You can download Python from [the official website]((https://www.python.org/downloads/)).

Follow the installation instructions for your operating system.

### 2. Clone the Repository

Clone this repository to your local machine using Git:

```zsh
git clone https://github.com/QiuYannnn/Local-File-Organizer.git
```

Or download the repository as a ZIP file and extract it to your desired location.

### 3. Set Up the Python Environment

Create a new Conda environment named `local_file_organizer` with Python 3.12:

```zsh
conda create --name local_file_organizer python=3.12
```

Activate the environment:

```zsh
conda activate local_file_organizer
```

### 4. Install Nexa SDK ï¸

#### CPU Installation
To install the CPU version of Nexa SDK, run:
```bash
pip install nexaai --prefer-binary --index-url https://nexaai.github.io/nexa-sdk/whl/cpu --extra-index-url https://pypi.org/simple --no-cache-dir
```

#### GPU Installation (Metal - macOS)
For the GPU version supporting Metal (macOS), run:
```bash
CMAKE_ARGS="-DGGML_METAL=ON -DSD_METAL=ON" pip install nexaai --prefer-binary --index-url https://nexaai.github.io/nexa-sdk/whl/metal --extra-index-url https://pypi.org/simple --no-cache-dir
```
For detailed installation instructions of Nexa SDK for **CUDA** and **AMD GPU** support, please refer to the [Installation section](https://github.com/NexaAI/nexa-sdk?tab=readme-ov-file#installation) in the main README.


### 5. Install Dependencies

1. Ensure you are in the project directory:
   ```zsh
   cd path/to/Local-File-Organizer
   ```
   Replace `path/to/Local-File-Organizer` with the actual path where you cloned or extracted the project.

2. Install the required dependencies:
   ```zsh
   pip install -r requirements.txt
   ```

**Note:** If you encounter issues with any packages, install them individually:

```zsh
pip install nexa Pillow pytesseract PyMuPDF python-docx
```

With the environment activated and dependencies installed, run the script using:

### 6. Running the ScriptðŸŽ‰
```zsh
python main.py
```

# Docker Installation ðŸ³

You can easily set up the project in a containerized environment using the provided `Dockerfile` and `docker-compose.yml`. This allows you to avoid manual dependencies and complicated setups, while keeping everything isolated in Docker containers.

## Steps to Install and Run the Project in Docker

Follow the instructions below to get started.

---

### 1. Clone the Repository

First, clone the repository and navigate into the project's directory:

```bash
git clone https://github.com/QiuYannnn/Local-File-Organizer.git
cd Local-File-Organizer
```

### 2. Build the Docker Image

Use the following command to build the Docker image and start the container. The `docker-compose` file automatically handles the build process:

```bash
docker-compose up --build
```

This step will:

- Automatically download, install, and configure all required dependencies.
- Take care of CUDA runtime libraries, Nvidia drivers, `nvidia-smi`, and other GPU-related setups if necessary.

You don't need to install any of these dependencies manuallyâ€”Docker will handle everything during the image build process.

> ðŸ’¡ **Note:** Optionally, to avoid re-downloading pre-trained models, you can mount your local `.cache` directory to the Docker containerâ€™s `.cache` directory. This will save time if you already have certain models downloaded:
>
> Example of how to mount the folder:
>
> ```yaml
> volumes:
>   - /path/to/your/.cache:/root/.cache
> ```

### That's it! ðŸŽ‰

Youâ€™re now ready to  run and develop the project inside a fully containerized environment. No worries about manually installing dependencies or compatibility issues across systems.

## Notes

- **SDK Models:**
  - The script uses `NexaVLMInference` and `NexaTextInference` models [usage](https://docs.nexaai.com/sdk/python-interface/gguf).
  - Ensure you have access to these models and they are correctly set up.
  - You may need to download model files or configure paths.


- **Dependencies:**
  - **pytesseract:** Requires Tesseract OCR installed on your system.
    - **macOS:** `brew install tesseract`
    - **Ubuntu/Linux:** `sudo apt-get install tesseract-ocr`
    - **Windows:** Download from [Tesseract OCR Windows Installer](https://github.com/UB-Mannheim/tesseract/wiki)
  - **PyMuPDF (fitz):** Used for reading PDFs.

- **Processing Time:**
  - Processing may take time depending on the number and size of files.
  - The script uses multiprocessing to improve performance.

- **Customizing Prompts:**
  - You can adjust prompts in `data_processing.py` to change how metadata is generated.

## License

This project is dual-licensed under the MIT License and Apache 2.0 License. You may choose which license you prefer to use for this project.

- See the [MIT License](LICENSE-MIT) for more details.